{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing noncoding variation associated with disease is a major application of Basenji. I now offer several tools to enable that analysis. If you have a small set of variants and know what datasets are most relevant, [basenji_sat_vcf.py](https://github.com/calico/basenji/blob/master/bin/basenji_sat_vcf.py) lets you perform a saturation mutagenesis of the variant and surrounding region to see the relevant nearby motifs.\n",
    "\n",
    "If you want scores measuring the influence of those variants on all datasets,\n",
    " * [basenji_sad.py](https://github.com/calico/basenji/blob/master/bin/basenji_sad.py) computes my SNP activity difference (SAD) score--the predicted change in aligned fragments to the region.\n",
    " * [basenji_sed.py](https://github.com/calico/basenji/blob/master/bin/basenji_sed.py) computes my SNP expression difference (SED) score--the predicted change in aligned fragments to gene TSS's.\n",
    "\n",
    "Here, I'll demonstrate those two programs. You'll need\n",
    " * Trained model\n",
    " * Input file (FASTA or HDF5 with test_in/test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you can either train your own model in the [Train/test tutorial](https://github.com/calico/basenji/blob/master/tutorials/train_test.ipynb) or use one that I pre-trained from the models subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we'll study a prostate cancer susceptibility allele of rs339331 that increases RFX6 expression by modulating HOXB13 chromatin binding (http://www.nature.com/ng/journal/v46/n2/full/ng.2862.html).\n",
    "\n",
    "First, we'll use [basenji_sad.py](https://github.com/calico/basenji/blob/master/bin/basenji_sad.py) to predict across the region for each allele and compute stats about the mean and max differences.\n",
    "\n",
    "The most relevant options are:\n",
    "\n",
    "| Option/Argument | Value | Note |\n",
    "|:---|:---|:---|\n",
    "| -f | data/hg19.ml.fa | Genome fasta. |\n",
    "| -g | data/human.hg19.genome | Genome assembly chromosome length to bound gene sequences. |\n",
    "| -l | 262144 | Saturation mutagenesis region in the center of the given sequence(s) |\n",
    "| -o | rfx6_sad | Outplot plot directory. |\n",
    "| --rc | | Predict forward and reverse complement versions and average the results. |\n",
    "| -t | data/gm12878_wigs.txt | Target labels. |\n",
    "| params_file | models/params_med.txt | Table of parameters to setup the model architecture and optimization parameters. |\n",
    "| model_file | models/gm12878.tf | Trained saved model prefix. |\n",
    "| vcf_file | data/rs339331.vcf | VCF file specifying variants to score. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_buffer': 16384, 'loss': 'poisson', 'cnn_dense': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0], 'adam_beta1': 0.97, 'cnn_dropout': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1], 'cnn_dilation': [1, 1, 1, 1, 1, 1, 2, 4, 8, 16, 32, 64, 128, 1], 'adam_beta2': 0.98, 'link': 'softplus', 'target_pool': 128, 'cnn_filter_sizes': [22, 1, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'batch_renorm': 1, 'cnn_pool': [1, 2, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'cnn_filters': [196, 196, 235, 282, 338, 384, 64, 64, 64, 64, 64, 64, 64, 512], 'num_targets': 39, 'batch_size': 1, 'learning_rate': 0.002}\n",
      "Targets pooled by 128 to length 2048\n",
      "Convolution w/ 196 4x22 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 196 196x1 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 2\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 235 196x6 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 4\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 282 235x6 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 4\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 338 282x6 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 4\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 384 338x3 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 384x3 filters strided 1, dilated 2\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 448x3 filters strided 1, dilated 4\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 512x3 filters strided 1, dilated 8\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 576x3 filters strided 1, dilated 16\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 640x3 filters strided 1, dilated 32\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 704x3 filters strided 1, dilated 64\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 768x3 filters strided 1, dilated 128\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 512 832x3 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.100\n",
      "Convolution w/ 39 512x1 filters to final targets\n",
      "Model building time 15.292389\n",
      "2017-09-16 10:02:43.905296: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-16 10:02:43.905319: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-16 10:02:43.905324: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-16 10:02:43.905328: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    }
   ],
   "source": [
    "! basenji_sad.py -f data/hg19.ml.fa -g data/human.hg19.genome -l 262144 -o rfx6_sad --rc -t data/gm12878_wigs.txt models/params_med.txt models/gm12878.tf data/rs339331.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfx6_sad/sad_table.txt now contains a table describing the results.\n",
    "\n",
    "The *u* in *upred* and *usad* refers to taking the mean across the sequence, whereas *x* in *xpred* and *xsad* refers to the maximum position. \n",
    "Then *sad* refers to subtracting the alt allele prediction from the ref allele, and *sar* refers to adding a pseudocount 1 and taking log2 of their ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsid index score ref alt ref_upred alt_upred usad usar ref_xpred alt_xpred xsad xsar target_index target_id target_label\r\n",
      "rs339331      .                 .      T      C  4.469  4.469  0.0000  0.0000  4.383  4.422  0.0391  0.0104    0 ENCSR000EJD_3_1 DNASE:GM12878\r\n",
      "rs339331      .                 .      T      C  1.628  1.628  0.0000  0.0000  1.690  1.758  0.0674  0.0357    1 ENCSR000EMT_2_1 DNASE:GM12878\r\n",
      "rs339331      .                 .      T      C  0.658  0.658  0.0000  0.0000  0.694  0.721  0.0273  0.0231    2 ENCSR000EMT_1_1 DNASE:GM12878\r\n",
      "rs339331      .                 .      T      C  4.332  4.332  0.0000  0.0000  4.004  4.055  0.0508  0.0146    3 ENCSR000EJD_1_1 DNASE:GM12878\r\n",
      "rs339331      .                 .      T      C  2.797  2.799  0.0020  0.0010  2.332  2.342  0.0098  0.0042    4 ENCSR000EJD_2_1 DNASE:GM12878\r\n",
      "rs339331      .                 .      T      C  1.744  1.744  0.0000  0.0000  1.424  1.438  0.0137  0.0081    5 ENCSR057BWO_2_1 HISTONE:H3K4me3 GM12878\r\n",
      "rs339331      .                 .      T      C  0.531  0.531  0.0000  0.0000  0.401  0.422  0.0215  0.0220    6 ENCSR000AKE_1_1 HISTONE:H3K36me3 GM12878\r\n",
      "rs339331      .                 .      T      C  0.218  0.218  0.0000  0.0000  0.186  0.197  0.0116  0.0140    7 ENCSR000AKF_2_1 HISTONE:H3K4me1 GM12878\r\n",
      "rs339331      .                 .      T      C  0.485  0.485  0.0000  0.0000  0.611  0.625  0.0142  0.0126    8 ENCSR000AOV_2_1 HISTONE:H2AFZ GM12878\r\n"
     ]
    }
   ],
   "source": [
    "! head rfx6_sad/sad_table.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort by *xsar* to get an idea of the datasets where Basenji sees the largest difference between the two alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsid index score ref alt ref_upred alt_upred usad usar ref_xpred alt_xpred xsad xsar target_index target_id target_label\r\n",
      "rs339331      .                 .      T      C  1.391  1.391  0.0000  0.0000  1.733  1.704 -0.0293 -0.0155   21 ENCSR057BWO_1_1 HISTONE:H3K4me3 GM12878\r\n",
      "rs339331      .                 .      T      C  0.087  0.087  0.0000  0.0000  0.632  0.629 -0.0029 -0.0026   38    CNhs12331 CAGE:B lymphoblastoid cell line: GM12878 ENCODE, biol_rep1\r\n",
      "rs339331      .                 .      T      C  0.073  0.073  0.0000  0.0000  0.544  0.542 -0.0024 -0.0023   36    CNhs12332 CAGE:B lymphoblastoid cell line: GM12878 ENCODE, biol_rep2\r\n",
      "rs339331      .                 .      T      C  0.220  0.220  0.0000  0.0000  0.342  0.340 -0.0020 -0.0021   33 ENCSR000AKH_2_1 HISTONE:H3K9ac GM12878\r\n"
     ]
    }
   ],
   "source": [
    "! sort -k13 -g rfx6_sad/sad_table.txt | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs339331      .                 .      T      C  1.628  1.628  0.0000  0.0000  1.690  1.758  0.0674  0.0357    1 ENCSR000EMT_2_1 DNASE:GM12878\r\n",
      "rs339331      .                 .      T      C  0.664  0.664  0.0000  0.0000  0.527  0.562  0.0356  0.0333   24 ENCSR000DRX_2_1 HISTONE:H3K27me3 GM12878\r\n",
      "rs339331      .                 .      T      C  0.469  0.469  0.0000  0.0000  0.508  0.541  0.0327  0.0310   29 ENCSR000DRX_1_1 HISTONE:H3K27me3 GM12878\r\n",
      "rs339331      .                 .      T      C  0.404  0.404  0.0000  0.0000  0.369  0.398  0.0293  0.0306   16 ENCSR000DRW_2_1 HISTONE:H3K36me3 GM12878\r\n",
      "rs339331      .                 .      T      C  0.405  0.405  0.0000  0.0000  0.364  0.392  0.0276  0.0289   12 ENCSR000DRW_1_1 HISTONE:H3K36me3 GM12878\r\n"
     ]
    }
   ],
   "source": [
    "! sort -k13 -gr rfx6_sad/sad_table.txt | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are inconclusive small effect sizes, not surprising given that we're only studying GM12878. The proper cell types would shed more light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can directly query the predictions at gene TSS's using [basenji_sed.py](https://github.com/calico/basenji/blob/master/bin/basenji_sed.py).\n",
    "\n",
    "[basenji_sed.py](https://github.com/calico/basenji/blob/master/bin/basenji_sed.py) takes as input the gene sequence HDF5 format described in [genes.ipynb](https://github.com/calico/basenji/blob/master/tutorials/genes.ipynb). There's no harm to providing an HDF5 that describes all genes, but it's too big to easily move around so I constructed one that focuses on RFX6.\n",
    "\n",
    "The most relevant options are:\n",
    "\n",
    "| Option/Argument | Value | Note |\n",
    "|:---|:---|:---|\n",
    "| -g | data/human.hg19.genome | Genome assembly chromosome length to bound gene sequences. |\n",
    "| -o | rfx6_sed | Outplot plot directory. |\n",
    "| --rc | | Predict forward and reverse complement versions and average the results. |\n",
    "| -w | 128 | Sequence bin width at which predictions are made. |\n",
    "| params_file | models/params_med.txt | Table of parameters to setup the model architecture and optimization parameters. |\n",
    "| model_file | models/gm12878.tf | Trained saved model prefix. |\n",
    "| genes_hdf5_file | data/rfx6.h5 | HDF5 file specifying gene sequences to query. |\n",
    "| vcf_file | data/rs339331.vcf | VCF file specifying variants to score. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersecting gene sequences with SNPs...done\n",
      "{'cnn_pool': [1, 2, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'adam_beta1': 0.97, 'cnn_dilation': [1, 1, 1, 1, 1, 1, 2, 4, 8, 16, 32, 64, 128, 1], 'target_pool': 128, 'link': 'softplus', 'cnn_filters': [196, 196, 235, 282, 338, 384, 64, 64, 64, 64, 64, 64, 64, 512], 'num_targets': 39, 'adam_beta2': 0.98, 'cnn_filter_sizes': [22, 1, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'loss': 'poisson', 'batch_size': 1, 'cnn_dropout': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1], 'batch_renorm': 1, 'learning_rate': 0.002, 'cnn_dense': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0], 'batch_buffer': 16384}\n",
      "Targets pooled by 128 to length 2048\n",
      "Convolution w/ 196 4x22 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 196 196x1 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 2\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 235 196x6 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 4\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 282 235x6 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 4\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 338 282x6 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Max pool 4\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 384 338x3 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 384x3 filters strided 1, dilated 2\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 448x3 filters strided 1, dilated 4\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 512x3 filters strided 1, dilated 8\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 576x3 filters strided 1, dilated 16\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 640x3 filters strided 1, dilated 32\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 704x3 filters strided 1, dilated 64\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 64 768x3 filters strided 1, dilated 128\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.050\n",
      "Convolution w/ 512 832x3 filters strided 1, dilated 1\n",
      "Batch normalization\n",
      "ReLU\n",
      "Dropout w/ probability 0.100\n",
      "Convolution w/ 39 39x1 filters to final targets\n",
      "2017-09-24 17:34:44.179881: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-24 17:34:44.179917: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-24 17:34:44.179926: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-24 17:34:44.179933: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    }
   ],
   "source": [
    "! basenji_sed.py -g data/human.hg19.genome -o rfx6_sed --rc -w 128 models/params_med.txt models/gm12878.tf data/rfx6.h5 data/rs339331.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsid ref alt gene tss_dist ref_pred alt_pred sed ser target_index target_id target_label\r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 11.9669 11.9147 -0.0522 -0.0058   38          t38 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565  9.9741  9.9313 -0.0428 -0.0056   36          t36 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 10.3157 10.2733 -0.0424 -0.0054   37          t37 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 32.7165 32.5909 -0.1256 -0.0054   22          t22 \r\n"
     ]
    }
   ],
   "source": [
    "! sort -k9 -g rfx6_sed/sed_gene.txt | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs339331      T     C ENSG00000185002.9_1 11565 168.9414 169.1487  0.2073  0.0018   14          t14 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 135.2241 135.3682  0.1440  0.0015   24          t24 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 95.2887 95.3773  0.0886  0.0013   29          t29 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 65.0739 65.1327  0.0588  0.0013   26          t26 \r\n",
      "rs339331      T     C ENSG00000185002.9_1 11565 57.9192 57.9313  0.0121  0.0003   32          t32 \r\n"
     ]
    }
   ],
   "source": [
    "! sort -k9 -gr rfx6_sed/sed_gene.txt | head -n 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
